{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c998074-8278-42e6-89ec-df7f924ba110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "\n",
    "paddle.set_device('gpu')\n",
    "paddle.set_default_dtype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5619bae-1a6b-4945-9242-a3ab2cc9aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "\n",
    "def getitem(dict, index):\n",
    "    label = a[b\"labels\"][index]\n",
    "    image_data = a[b\"data\"][index]\n",
    "    red_channel = image_data[:1024].reshape((32, 32))\n",
    "    green_channel = image_data[1024:2048].reshape((32, 32))\n",
    "    blue_channel = image_data[2048:].reshape((32, 32))\n",
    "    rgb_image = np.dstack((red_channel, green_channel, blue_channel))\n",
    "    return rgb_image, label\n",
    "\n",
    "\n",
    "label_names = unpickle(\"../data/cifar-10-batches-py/batches.meta\")[b\"label_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18b219e-46fc-4ef4-b8b2-729b850492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader(paddle.io.Dataset):\n",
    "    def __init__(self, *path):\n",
    "        super().__init__()\n",
    "        data = unpickle(path[0])\n",
    "        self.x = data[b\"data\"] / 255\n",
    "        self.y = data[b\"labels\"]\n",
    "        for i in range(1, len(path)):\n",
    "            data = unpickle(path[i])\n",
    "            self.x = np.concatenate((self.x, data[b\"data\"] / 255))\n",
    "            self.y = np.concatenate((self.y, data[b\"labels\"]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4e509-9bca-4c52-b09b-03860a8f9a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf6af48-c9e0-4566-a319-edfd5dc980a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.fc1 = paddle.nn.Linear(3072, 1024)\n",
    "        self.relu1 = paddle.nn.ReLU()\n",
    "        self.fc2 = paddle.nn.Linear(1024, 512)\n",
    "        self.relu2 = paddle.nn.ReLU()\n",
    "        self.fc3 = paddle.nn.Linear(512, 256)\n",
    "        self.relu3 = paddle.nn.ReLU()\n",
    "        self.fc4 = paddle.nn.Linear(256, 128)\n",
    "        self.relu4 = paddle.nn.ReLU()\n",
    "        self.fc5 = paddle.nn.Linear(128, 64)\n",
    "        self.relu5 = paddle.nn.ReLU()\n",
    "        self.fc6 = paddle.nn.Linear(64, 32)\n",
    "        self.relu6 = paddle.nn.ReLU()\n",
    "        self.fc7 = paddle.nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.fc7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8a0879-dd31-40e4-8f64-b6e4b5c20c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDNN()\n",
    "cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "opt = paddle.optimizer.SGD(0.01, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f896f-5749-47cc-961b-e34262a6f7db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \tbatch 0 \tloss 2.28 \taccuracy 0.10\n",
      "epoch 0 \tbatch 100 \tloss 2.27 \taccuracy 0.20\n",
      "epoch 0 \tbatch 200 \tloss 2.26 \taccuracy 0.00\n",
      "epoch 0 \tbatch 300 \tloss 1.87 \taccuracy 0.40\n",
      "epoch 0 \tbatch 400 \tloss 1.85 \taccuracy 0.30\n",
      "epoch 0 \tbatch 500 \tloss 2.28 \taccuracy 0.20\n",
      "epoch 0 \tbatch 600 \tloss 1.95 \taccuracy 0.30\n",
      "epoch 0 \tbatch 700 \tloss 1.91 \taccuracy 0.30\n",
      "epoch 0 \tbatch 800 \tloss 1.83 \taccuracy 0.20\n",
      "epoch 0 \tbatch 900 \tloss 1.91 \taccuracy 0.20\n",
      "epoch 0 \tbatch 1000 \tloss 2.17 \taccuracy 0.40\n",
      "epoch 0 \tbatch 1100 \tloss 2.26 \taccuracy 0.10\n",
      "epoch 0 \tbatch 1200 \tloss 1.86 \taccuracy 0.30\n",
      "epoch 0 \tbatch 1300 \tloss 2.08 \taccuracy 0.30\n",
      "epoch 0 \tbatch 1400 \tloss 1.70 \taccuracy 0.30\n",
      "epoch 0 \tbatch 1500 \tloss 1.75 \taccuracy 0.40\n",
      "epoch 0 \tbatch 1600 \tloss 2.06 \taccuracy 0.10\n",
      "epoch 0 \tbatch 1700 \tloss 1.95 \taccuracy 0.50\n",
      "epoch 0 \tbatch 1800 \tloss 2.15 \taccuracy 0.20\n",
      "epoch 0 \tbatch 1900 \tloss 2.39 \taccuracy 0.10\n",
      "epoch 0 \tbatch 2000 \tloss 1.91 \taccuracy 0.40\n",
      "epoch 0 \tbatch 2100 \tloss 1.47 \taccuracy 0.60\n",
      "epoch 0 \tbatch 2200 \tloss 1.72 \taccuracy 0.50\n",
      "epoch 0 \tbatch 2300 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 0 \tbatch 2400 \tloss 1.98 \taccuracy 0.20\n",
      "epoch 0 \tbatch 2500 \tloss 2.02 \taccuracy 0.20\n",
      "epoch 0 \tbatch 2600 \tloss 1.98 \taccuracy 0.20\n",
      "epoch 0 \tbatch 2700 \tloss 1.92 \taccuracy 0.30\n",
      "epoch 0 \tbatch 2800 \tloss 1.43 \taccuracy 0.60\n",
      "epoch 0 \tbatch 2900 \tloss 1.63 \taccuracy 0.40\n",
      "epoch 0 \tbatch 3000 \tloss 2.05 \taccuracy 0.30\n",
      "epoch 0 \tbatch 3100 \tloss 1.31 \taccuracy 0.60\n",
      "epoch 0 \tbatch 3200 \tloss 1.68 \taccuracy 0.20\n",
      "epoch 0 \tbatch 3300 \tloss 2.10 \taccuracy 0.20\n",
      "epoch 0 \tbatch 3400 \tloss 2.16 \taccuracy 0.20\n",
      "epoch 0 \tbatch 3500 \tloss 1.63 \taccuracy 0.30\n",
      "epoch 0 \tbatch 3600 \tloss 1.88 \taccuracy 0.30\n",
      "epoch 0 \tbatch 3700 \tloss 1.61 \taccuracy 0.40\n",
      "epoch 0 \tbatch 3800 \tloss 1.49 \taccuracy 0.70\n",
      "epoch 0 \tbatch 3900 \tloss 1.78 \taccuracy 0.40\n",
      "epoch 0 \tbatch 4000 \tloss 2.06 \taccuracy 0.20\n",
      "epoch 0 \tbatch 4100 \tloss 1.44 \taccuracy 0.50\n",
      "epoch 0 \tbatch 4200 \tloss 1.84 \taccuracy 0.40\n",
      "epoch 0 \tbatch 4300 \tloss 1.36 \taccuracy 0.50\n",
      "epoch 0 \tbatch 4400 \tloss 1.50 \taccuracy 0.40\n",
      "epoch 0 \tbatch 4500 \tloss 1.57 \taccuracy 0.60\n",
      "epoch 0 \tbatch 4600 \tloss 1.44 \taccuracy 0.70\n",
      "epoch 0 \tbatch 4700 \tloss 1.86 \taccuracy 0.40\n",
      "epoch 0 \tbatch 4800 \tloss 1.84 \taccuracy 0.30\n",
      "epoch 0 \tbatch 4900 \tloss 1.39 \taccuracy 0.50\n",
      "Train Accuracy: 0.32326%\n",
      "Epoch: 0, Loss: 0.18594872912651025\n",
      "epoch 1 \tbatch 0 \tloss 1.58 \taccuracy 0.40\n",
      "epoch 1 \tbatch 100 \tloss 1.82 \taccuracy 0.50\n",
      "epoch 1 \tbatch 200 \tloss 2.02 \taccuracy 0.40\n",
      "epoch 1 \tbatch 300 \tloss 1.64 \taccuracy 0.50\n",
      "epoch 1 \tbatch 400 \tloss 2.14 \taccuracy 0.10\n",
      "epoch 1 \tbatch 500 \tloss 2.30 \taccuracy 0.20\n",
      "epoch 1 \tbatch 600 \tloss 1.34 \taccuracy 0.30\n",
      "epoch 1 \tbatch 700 \tloss 1.85 \taccuracy 0.10\n",
      "epoch 1 \tbatch 800 \tloss 1.70 \taccuracy 0.50\n",
      "epoch 1 \tbatch 900 \tloss 1.45 \taccuracy 0.70\n",
      "epoch 1 \tbatch 1000 \tloss 1.14 \taccuracy 0.70\n",
      "epoch 1 \tbatch 1100 \tloss 1.47 \taccuracy 0.40\n",
      "epoch 1 \tbatch 1200 \tloss 1.73 \taccuracy 0.20\n",
      "epoch 1 \tbatch 1300 \tloss 1.64 \taccuracy 0.40\n",
      "epoch 1 \tbatch 1400 \tloss 1.45 \taccuracy 0.60\n",
      "epoch 1 \tbatch 1500 \tloss 1.56 \taccuracy 0.50\n",
      "epoch 1 \tbatch 1600 \tloss 1.66 \taccuracy 0.40\n",
      "epoch 1 \tbatch 1700 \tloss 1.24 \taccuracy 0.80\n",
      "epoch 1 \tbatch 1800 \tloss 2.14 \taccuracy 0.30\n",
      "epoch 1 \tbatch 1900 \tloss 1.70 \taccuracy 0.30\n",
      "epoch 1 \tbatch 2000 \tloss 1.29 \taccuracy 0.40\n",
      "epoch 1 \tbatch 2100 \tloss 2.03 \taccuracy 0.40\n",
      "epoch 1 \tbatch 2200 \tloss 1.85 \taccuracy 0.20\n",
      "epoch 1 \tbatch 2300 \tloss 1.60 \taccuracy 0.30\n",
      "epoch 1 \tbatch 2400 \tloss 1.66 \taccuracy 0.10\n",
      "epoch 1 \tbatch 2500 \tloss 0.73 \taccuracy 1.00\n",
      "epoch 1 \tbatch 2600 \tloss 1.77 \taccuracy 0.30\n",
      "epoch 1 \tbatch 2700 \tloss 1.95 \taccuracy 0.30\n",
      "epoch 1 \tbatch 2800 \tloss 1.73 \taccuracy 0.30\n",
      "epoch 1 \tbatch 2900 \tloss 2.03 \taccuracy 0.20\n",
      "epoch 1 \tbatch 3000 \tloss 2.00 \taccuracy 0.10\n",
      "epoch 1 \tbatch 3100 \tloss 2.12 \taccuracy 0.10\n",
      "epoch 1 \tbatch 3200 \tloss 1.97 \taccuracy 0.20\n",
      "epoch 1 \tbatch 3300 \tloss 1.01 \taccuracy 0.60\n",
      "epoch 1 \tbatch 3400 \tloss 1.98 \taccuracy 0.10\n",
      "epoch 1 \tbatch 3500 \tloss 1.82 \taccuracy 0.40\n",
      "epoch 1 \tbatch 3600 \tloss 1.61 \taccuracy 0.40\n",
      "epoch 1 \tbatch 3700 \tloss 2.22 \taccuracy 0.30\n",
      "epoch 1 \tbatch 3800 \tloss 2.64 \taccuracy 0.10\n",
      "epoch 1 \tbatch 3900 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 1 \tbatch 4000 \tloss 1.62 \taccuracy 0.40\n",
      "epoch 1 \tbatch 4100 \tloss 2.03 \taccuracy 0.30\n",
      "epoch 1 \tbatch 4200 \tloss 1.62 \taccuracy 0.20\n",
      "epoch 1 \tbatch 4300 \tloss 1.50 \taccuracy 0.70\n",
      "epoch 1 \tbatch 4400 \tloss 1.33 \taccuracy 0.60\n",
      "epoch 1 \tbatch 4500 \tloss 1.74 \taccuracy 0.30\n",
      "epoch 1 \tbatch 4600 \tloss 0.95 \taccuracy 0.60\n",
      "epoch 1 \tbatch 4700 \tloss 1.73 \taccuracy 0.60\n",
      "epoch 1 \tbatch 4800 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 1 \tbatch 4900 \tloss 1.57 \taccuracy 0.40\n",
      "Train Accuracy: 0.4006%\n",
      "Epoch: 1, Loss: 0.16638499123775527\n",
      "epoch 2 \tbatch 0 \tloss 1.81 \taccuracy 0.30\n",
      "epoch 2 \tbatch 100 \tloss 1.18 \taccuracy 0.50\n",
      "epoch 2 \tbatch 200 \tloss 1.90 \taccuracy 0.20\n",
      "epoch 2 \tbatch 300 \tloss 1.16 \taccuracy 0.60\n",
      "epoch 2 \tbatch 400 \tloss 1.38 \taccuracy 0.40\n",
      "epoch 2 \tbatch 500 \tloss 1.80 \taccuracy 0.30\n",
      "epoch 2 \tbatch 600 \tloss 1.58 \taccuracy 0.50\n",
      "epoch 2 \tbatch 700 \tloss 1.37 \taccuracy 0.40\n",
      "epoch 2 \tbatch 800 \tloss 1.73 \taccuracy 0.20\n",
      "epoch 2 \tbatch 900 \tloss 2.07 \taccuracy 0.20\n",
      "epoch 2 \tbatch 1000 \tloss 1.54 \taccuracy 0.50\n",
      "epoch 2 \tbatch 1100 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 2 \tbatch 1200 \tloss 1.49 \taccuracy 0.60\n",
      "epoch 2 \tbatch 1300 \tloss 2.42 \taccuracy 0.30\n",
      "epoch 2 \tbatch 1400 \tloss 2.10 \taccuracy 0.40\n",
      "epoch 2 \tbatch 1500 \tloss 2.23 \taccuracy 0.20\n",
      "epoch 2 \tbatch 1600 \tloss 1.93 \taccuracy 0.20\n",
      "epoch 2 \tbatch 1700 \tloss 1.72 \taccuracy 0.50\n",
      "epoch 2 \tbatch 1800 \tloss 1.58 \taccuracy 0.50\n",
      "epoch 2 \tbatch 1900 \tloss 1.69 \taccuracy 0.30\n",
      "epoch 2 \tbatch 2000 \tloss 1.76 \taccuracy 0.40\n",
      "epoch 2 \tbatch 2100 \tloss 1.32 \taccuracy 0.60\n",
      "epoch 2 \tbatch 2200 \tloss 1.16 \taccuracy 0.60\n",
      "epoch 2 \tbatch 2300 \tloss 1.41 \taccuracy 0.60\n",
      "epoch 2 \tbatch 2400 \tloss 1.32 \taccuracy 0.60\n",
      "epoch 2 \tbatch 2500 \tloss 1.85 \taccuracy 0.40\n",
      "epoch 2 \tbatch 2600 \tloss 1.45 \taccuracy 0.60\n",
      "epoch 2 \tbatch 2700 \tloss 1.85 \taccuracy 0.30\n",
      "epoch 2 \tbatch 2800 \tloss 1.35 \taccuracy 0.50\n",
      "epoch 2 \tbatch 2900 \tloss 1.40 \taccuracy 0.60\n",
      "epoch 2 \tbatch 3000 \tloss 1.17 \taccuracy 0.50\n",
      "epoch 2 \tbatch 3100 \tloss 2.27 \taccuracy 0.20\n",
      "epoch 2 \tbatch 3200 \tloss 1.49 \taccuracy 0.40\n",
      "epoch 2 \tbatch 3300 \tloss 1.69 \taccuracy 0.20\n",
      "epoch 2 \tbatch 3400 \tloss 2.39 \taccuracy 0.20\n",
      "epoch 2 \tbatch 3500 \tloss 1.45 \taccuracy 0.40\n",
      "epoch 2 \tbatch 3600 \tloss 1.42 \taccuracy 0.50\n",
      "epoch 2 \tbatch 3700 \tloss 1.37 \taccuracy 0.60\n",
      "epoch 2 \tbatch 3800 \tloss 1.40 \taccuracy 0.30\n",
      "epoch 2 \tbatch 3900 \tloss 1.13 \taccuracy 0.60\n",
      "epoch 2 \tbatch 4000 \tloss 1.82 \taccuracy 0.40\n",
      "epoch 2 \tbatch 4100 \tloss 1.21 \taccuracy 0.70\n",
      "epoch 2 \tbatch 4200 \tloss 1.34 \taccuracy 0.50\n",
      "epoch 2 \tbatch 4300 \tloss 1.94 \taccuracy 0.50\n",
      "epoch 2 \tbatch 4400 \tloss 2.39 \taccuracy 0.10\n",
      "epoch 2 \tbatch 4500 \tloss 2.18 \taccuracy 0.30\n",
      "epoch 2 \tbatch 4600 \tloss 1.45 \taccuracy 0.50\n",
      "epoch 2 \tbatch 4700 \tloss 1.44 \taccuracy 0.60\n",
      "epoch 2 \tbatch 4800 \tloss 1.00 \taccuracy 0.60\n",
      "epoch 2 \tbatch 4900 \tloss 1.83 \taccuracy 0.20\n",
      "Train Accuracy: 0.43698%\n",
      "Epoch: 2, Loss: 0.15747004323873326\n",
      "epoch 3 \tbatch 0 \tloss 0.97 \taccuracy 0.80\n",
      "epoch 3 \tbatch 100 \tloss 1.82 \taccuracy 0.30\n",
      "epoch 3 \tbatch 200 \tloss 1.66 \taccuracy 0.50\n",
      "epoch 3 \tbatch 300 \tloss 1.58 \taccuracy 0.30\n",
      "epoch 3 \tbatch 400 \tloss 1.36 \taccuracy 0.60\n",
      "epoch 3 \tbatch 500 \tloss 1.92 \taccuracy 0.50\n",
      "epoch 3 \tbatch 600 \tloss 1.16 \taccuracy 0.60\n",
      "epoch 3 \tbatch 700 \tloss 0.99 \taccuracy 0.80\n",
      "epoch 3 \tbatch 800 \tloss 1.25 \taccuracy 0.80\n",
      "epoch 3 \tbatch 900 \tloss 1.61 \taccuracy 0.30\n",
      "epoch 3 \tbatch 1000 \tloss 2.20 \taccuracy 0.30\n",
      "epoch 3 \tbatch 1100 \tloss 2.13 \taccuracy 0.30\n",
      "epoch 3 \tbatch 1200 \tloss 1.44 \taccuracy 0.60\n",
      "epoch 3 \tbatch 1300 \tloss 1.12 \taccuracy 0.70\n",
      "epoch 3 \tbatch 1400 \tloss 1.36 \taccuracy 0.40\n",
      "epoch 3 \tbatch 1500 \tloss 0.95 \taccuracy 0.70\n",
      "epoch 3 \tbatch 1600 \tloss 1.53 \taccuracy 0.40\n",
      "epoch 3 \tbatch 1700 \tloss 1.88 \taccuracy 0.40\n",
      "epoch 3 \tbatch 1800 \tloss 1.24 \taccuracy 0.40\n",
      "epoch 3 \tbatch 1900 \tloss 1.45 \taccuracy 0.60\n",
      "epoch 3 \tbatch 2000 \tloss 0.84 \taccuracy 0.80\n",
      "epoch 3 \tbatch 2100 \tloss 1.47 \taccuracy 0.50\n",
      "epoch 3 \tbatch 2200 \tloss 1.36 \taccuracy 0.40\n",
      "epoch 3 \tbatch 2300 \tloss 1.70 \taccuracy 0.50\n",
      "epoch 3 \tbatch 2400 \tloss 1.44 \taccuracy 0.50\n",
      "epoch 3 \tbatch 2500 \tloss 1.60 \taccuracy 0.50\n",
      "epoch 3 \tbatch 2600 \tloss 1.41 \taccuracy 0.60\n",
      "epoch 3 \tbatch 2700 \tloss 1.64 \taccuracy 0.40\n",
      "epoch 3 \tbatch 2800 \tloss 1.58 \taccuracy 0.50\n",
      "epoch 3 \tbatch 2900 \tloss 1.48 \taccuracy 0.60\n",
      "epoch 3 \tbatch 3000 \tloss 1.65 \taccuracy 0.50\n",
      "epoch 3 \tbatch 3100 \tloss 1.22 \taccuracy 0.70\n",
      "epoch 3 \tbatch 3200 \tloss 1.41 \taccuracy 0.40\n",
      "epoch 3 \tbatch 3300 \tloss 1.08 \taccuracy 0.60\n",
      "epoch 3 \tbatch 3400 \tloss 1.16 \taccuracy 0.50\n",
      "epoch 3 \tbatch 3500 \tloss 1.04 \taccuracy 0.60\n",
      "epoch 3 \tbatch 3600 \tloss 1.47 \taccuracy 0.50\n",
      "epoch 3 \tbatch 3700 \tloss 2.12 \taccuracy 0.40\n",
      "epoch 3 \tbatch 3800 \tloss 1.48 \taccuracy 0.30\n",
      "epoch 3 \tbatch 3900 \tloss 1.24 \taccuracy 0.50\n",
      "epoch 3 \tbatch 4000 \tloss 1.05 \taccuracy 0.60\n",
      "epoch 3 \tbatch 4100 \tloss 1.36 \taccuracy 0.60\n",
      "epoch 3 \tbatch 4200 \tloss 1.21 \taccuracy 0.60\n",
      "epoch 3 \tbatch 4300 \tloss 2.39 \taccuracy 0.10\n",
      "epoch 3 \tbatch 4400 \tloss 1.47 \taccuracy 0.50\n",
      "epoch 3 \tbatch 4500 \tloss 1.53 \taccuracy 0.50\n",
      "epoch 3 \tbatch 4600 \tloss 1.37 \taccuracy 0.40\n",
      "epoch 3 \tbatch 4700 \tloss 2.18 \taccuracy 0.10\n",
      "epoch 3 \tbatch 4800 \tloss 1.65 \taccuracy 0.50\n",
      "epoch 3 \tbatch 4900 \tloss 1.36 \taccuracy 0.70\n",
      "Train Accuracy: 0.4595%\n",
      "Epoch: 3, Loss: 0.1510433196960809\n",
      "epoch 4 \tbatch 0 \tloss 1.35 \taccuracy 0.50\n",
      "epoch 4 \tbatch 100 \tloss 1.01 \taccuracy 0.60\n",
      "epoch 4 \tbatch 200 \tloss 1.18 \taccuracy 0.20\n",
      "epoch 4 \tbatch 300 \tloss 1.74 \taccuracy 0.60\n",
      "epoch 4 \tbatch 400 \tloss 1.19 \taccuracy 0.60\n",
      "epoch 4 \tbatch 500 \tloss 1.47 \taccuracy 0.60\n",
      "epoch 4 \tbatch 600 \tloss 1.13 \taccuracy 0.60\n",
      "epoch 4 \tbatch 700 \tloss 1.78 \taccuracy 0.30\n",
      "epoch 4 \tbatch 800 \tloss 1.68 \taccuracy 0.60\n",
      "epoch 4 \tbatch 900 \tloss 1.12 \taccuracy 0.60\n",
      "epoch 4 \tbatch 1000 \tloss 1.66 \taccuracy 0.40\n",
      "epoch 4 \tbatch 1100 \tloss 1.58 \taccuracy 0.30\n",
      "epoch 4 \tbatch 1200 \tloss 1.62 \taccuracy 0.10\n",
      "epoch 4 \tbatch 1300 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 4 \tbatch 1400 \tloss 1.51 \taccuracy 0.50\n",
      "epoch 4 \tbatch 1500 \tloss 1.57 \taccuracy 0.60\n",
      "epoch 4 \tbatch 1600 \tloss 1.94 \taccuracy 0.30\n",
      "epoch 4 \tbatch 1700 \tloss 1.38 \taccuracy 0.40\n",
      "epoch 4 \tbatch 1800 \tloss 0.97 \taccuracy 0.70\n",
      "epoch 4 \tbatch 1900 \tloss 1.36 \taccuracy 0.60\n",
      "epoch 4 \tbatch 2000 \tloss 1.81 \taccuracy 0.50\n",
      "epoch 4 \tbatch 2100 \tloss 1.67 \taccuracy 0.50\n",
      "epoch 4 \tbatch 2200 \tloss 1.73 \taccuracy 0.50\n",
      "epoch 4 \tbatch 2300 \tloss 0.98 \taccuracy 0.60\n",
      "epoch 4 \tbatch 2400 \tloss 1.73 \taccuracy 0.40\n",
      "epoch 4 \tbatch 2500 \tloss 1.29 \taccuracy 0.60\n",
      "epoch 4 \tbatch 2600 \tloss 1.75 \taccuracy 0.40\n",
      "epoch 4 \tbatch 2700 \tloss 0.93 \taccuracy 0.60\n",
      "epoch 4 \tbatch 2800 \tloss 1.67 \taccuracy 0.50\n",
      "epoch 4 \tbatch 2900 \tloss 1.54 \taccuracy 0.50\n",
      "epoch 4 \tbatch 3000 \tloss 1.59 \taccuracy 0.40\n",
      "epoch 4 \tbatch 3100 \tloss 1.58 \taccuracy 0.40\n",
      "epoch 4 \tbatch 3200 \tloss 1.60 \taccuracy 0.60\n",
      "epoch 4 \tbatch 3300 \tloss 1.26 \taccuracy 0.80\n",
      "epoch 4 \tbatch 3400 \tloss 1.21 \taccuracy 0.60\n",
      "epoch 4 \tbatch 3500 \tloss 1.60 \taccuracy 0.50\n",
      "epoch 4 \tbatch 3600 \tloss 2.29 \taccuracy 0.20\n",
      "epoch 4 \tbatch 3700 \tloss 1.24 \taccuracy 0.60\n",
      "epoch 4 \tbatch 3800 \tloss 1.08 \taccuracy 0.80\n",
      "epoch 4 \tbatch 3900 \tloss 1.89 \taccuracy 0.50\n",
      "epoch 4 \tbatch 4000 \tloss 0.99 \taccuracy 0.70\n",
      "epoch 4 \tbatch 4100 \tloss 1.16 \taccuracy 0.60\n",
      "epoch 4 \tbatch 4200 \tloss 1.27 \taccuracy 0.50\n",
      "epoch 4 \tbatch 4300 \tloss 1.22 \taccuracy 0.70\n",
      "epoch 4 \tbatch 4400 \tloss 0.85 \taccuracy 0.60\n",
      "epoch 4 \tbatch 4500 \tloss 1.27 \taccuracy 0.40\n",
      "epoch 4 \tbatch 4600 \tloss 2.14 \taccuracy 0.20\n",
      "epoch 4 \tbatch 4700 \tloss 1.29 \taccuracy 0.60\n",
      "epoch 4 \tbatch 4800 \tloss 1.66 \taccuracy 0.50\n",
      "epoch 4 \tbatch 4900 \tloss 1.65 \taccuracy 0.40\n",
      "Train Accuracy: 0.4752%\n",
      "Epoch: 4, Loss: 0.1462488332733216\n",
      "epoch 5 \tbatch 0 \tloss 1.96 \taccuracy 0.30\n",
      "epoch 5 \tbatch 100 \tloss 1.08 \taccuracy 0.70\n",
      "epoch 5 \tbatch 200 \tloss 1.51 \taccuracy 0.60\n",
      "epoch 5 \tbatch 300 \tloss 1.21 \taccuracy 0.50\n",
      "epoch 5 \tbatch 400 \tloss 1.39 \taccuracy 0.60\n",
      "epoch 5 \tbatch 500 \tloss 1.54 \taccuracy 0.30\n",
      "epoch 5 \tbatch 600 \tloss 1.60 \taccuracy 0.50\n",
      "epoch 5 \tbatch 700 \tloss 1.30 \taccuracy 0.60\n",
      "epoch 5 \tbatch 800 \tloss 1.36 \taccuracy 0.60\n",
      "epoch 5 \tbatch 900 \tloss 1.35 \taccuracy 0.60\n",
      "epoch 5 \tbatch 1000 \tloss 1.37 \taccuracy 0.60\n",
      "epoch 5 \tbatch 1100 \tloss 1.28 \taccuracy 0.70\n",
      "epoch 5 \tbatch 1200 \tloss 1.46 \taccuracy 0.50\n",
      "epoch 5 \tbatch 1300 \tloss 1.29 \taccuracy 0.30\n",
      "epoch 5 \tbatch 1400 \tloss 2.03 \taccuracy 0.30\n",
      "epoch 5 \tbatch 1500 \tloss 1.28 \taccuracy 0.60\n",
      "epoch 5 \tbatch 1600 \tloss 1.87 \taccuracy 0.50\n",
      "epoch 5 \tbatch 1700 \tloss 1.14 \taccuracy 0.60\n",
      "epoch 5 \tbatch 1800 \tloss 1.46 \taccuracy 0.30\n",
      "epoch 5 \tbatch 1900 \tloss 1.57 \taccuracy 0.40\n",
      "epoch 5 \tbatch 2000 \tloss 0.72 \taccuracy 0.80\n",
      "epoch 5 \tbatch 2100 \tloss 2.50 \taccuracy 0.30\n",
      "epoch 5 \tbatch 2200 \tloss 1.62 \taccuracy 0.20\n",
      "epoch 5 \tbatch 2300 \tloss 0.73 \taccuracy 0.90\n",
      "epoch 5 \tbatch 2400 \tloss 1.34 \taccuracy 0.60\n",
      "epoch 5 \tbatch 2500 \tloss 1.90 \taccuracy 0.40\n",
      "epoch 5 \tbatch 2600 \tloss 0.94 \taccuracy 0.60\n",
      "epoch 5 \tbatch 2700 \tloss 1.41 \taccuracy 0.40\n",
      "epoch 5 \tbatch 2800 \tloss 0.96 \taccuracy 0.70\n",
      "epoch 5 \tbatch 2900 \tloss 1.61 \taccuracy 0.50\n",
      "epoch 5 \tbatch 3000 \tloss 1.67 \taccuracy 0.30\n",
      "epoch 5 \tbatch 3100 \tloss 1.26 \taccuracy 0.60\n",
      "epoch 5 \tbatch 3200 \tloss 1.64 \taccuracy 0.50\n",
      "epoch 5 \tbatch 3300 \tloss 1.19 \taccuracy 0.60\n",
      "epoch 5 \tbatch 3400 \tloss 1.54 \taccuracy 0.40\n",
      "epoch 5 \tbatch 3500 \tloss 1.84 \taccuracy 0.20\n",
      "epoch 5 \tbatch 3600 \tloss 1.21 \taccuracy 0.40\n",
      "epoch 5 \tbatch 3700 \tloss 2.09 \taccuracy 0.40\n",
      "epoch 5 \tbatch 3800 \tloss 0.95 \taccuracy 0.70\n",
      "epoch 5 \tbatch 3900 \tloss 0.87 \taccuracy 0.60\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 10\n",
    "batch = 10\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    Reader(\n",
    "        \"../data/cifar-10-batches-py/data_batch_1\",\n",
    "        \"../data/cifar-10-batches-py/data_batch_2\",\n",
    "        \"../data/cifar-10-batches-py/data_batch_3\",\n",
    "        \"../data/cifar-10-batches-py/data_batch_4\",\n",
    "        \"../data/cifar-10-batches-py/data_batch_5\",\n",
    "    ),\n",
    "    batch_size=batch,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "for e in range(epoch):\n",
    "    full_loss = 0\n",
    "    n_loss = 0\n",
    "    n_eval = 0\n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch\", e, \"\\tbatch\", i, end=\" \")\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = cross_entropy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        full_loss += loss.numpy()\n",
    "        n_loss += batch\n",
    "        opt.clear_grad()\n",
    "\n",
    "        mask = np.array(y_pred, copy=False).argmax(1) == y\n",
    "        co = mask.sum().numpy()\n",
    "        correct += co\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"\\tloss {loss.numpy():.2f} \\taccuracy {co/batch:.2f}\")\n",
    "    print(f\"Train Accuracy: {correct/n_loss}%\")\n",
    "    print(f\"Epoch: {e}, Loss: {full_loss / n_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea77ddf-d1b7-4d6e-aaee-e26bae6e4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.save(model.state_dict(), \"train2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e884e-5b03-4571-833a-ca33c8d066f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ad24c-0328-4ab8-883d-ffc8e67fd543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = MyDNN()\n",
    "m.set_state_dict(paddle.load(\"train2.model\"))\n",
    "m.eval()\n",
    "eval_loader = paddle.io.DataLoader(\n",
    "    Reader(\"../data/cifar-10-batches-py/test_batch\"), batch_size=1000, shuffle=True\n",
    ")\n",
    "\n",
    "accs = []\n",
    "for i, (x, y) in enumerate(eval_loader):\n",
    "    y_pred = m(x)\n",
    "    mask = np.array(y_pred, copy=False).argmax(1) == y\n",
    "    acc = mask.sum().numpy() / batch\n",
    "    print(i, acc)\n",
    "    accs.append(acc)\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7314e5-2b1d-42e8-a6c3-d45a04ef8c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c4dc3-cb08-4900-8294-64e584a2c5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afcdf6-e7c0-4ff0-8e33-c88220005084",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=unpickle(\"../data/cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab2888-fc7f-472c-bcd5-7c7a41096f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(100):\n",
    "    (x,y)=getitem(a,t)\n",
    "    # plt.imshow(x)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()\n",
    "    y_pred=np.array(m(paddle.Tensor(a[b'data'][t]/255))).argmax()\n",
    "    print(y==y_pred,\"\\t\",label_names[y],\"\\tpred:\",label_names[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7fc9b-7e66-49f2-ac58-ffa96860ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "m(paddle.Tensor(a[b'data'][1]/255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ec51e-ba76-44ad-b820-847fecc81d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca1b47-1344-4a3e-a08a-a3daf798fb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ec9d4-9bbb-4b42-a3d2-fee7183f0a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb5525-017a-41ac-8689-44bd19f17f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7bbaf-7bb0-4d6e-a2ec-a9cf5b7dd2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca52b3d-948f-4b8e-bd4b-a5102fedac93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dd3fb-6dd1-4c71-8155-1b039c591c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
